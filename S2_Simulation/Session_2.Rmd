---
title: 'Brussels Advanced training'
author: "Giles Innocent"
date: "2024-01-31"
output: html_document
#output: beamer_presentation
#output: powerpoint_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(runjags)
library(pander)
library(ggplot2)
```

## Introduction

- Building on the basic course.
- __NOT__ lecture:practical.
- More intro: practical or discussion.
- You'll get more out of it if you try the exercises __before__ looking at the sample code.
- Nothing Bayesian, or specific to diagnostic tests or latent class analyses (although it is particularly useful here)
- There is more than one way to code

## Simulation

- Why simulate?
- How to simulate
    + within JAGS
    + R or equivalent
    + from an identical model to the analysis model
    + from a different model to the analysis

## Simulating in R

- Functions like rbinom, rpois, rnorm, etc.
- All take a first parameter, n the number of data points you wish to simulate
- E.G. Hui-Walter paradigm:
```{R}
  set.seed(1)
  n.sim <- 1
  prev <- c(0.25, 0.8)
  Se.1 <- Se.2 <- 0.8
  Sp.1 <- Sp.2 <- 0.95
  n.sampled <- c(100, 100)
  test.results <- data.frame(pp=numeric(length(prev)),
                             pn=numeric(length(prev)),
                             np=numeric(length(prev)),
                             nn=numeric(length(prev)))
  for(pop in 1:length(prev)){
    n.pos <- rbinom(n.sim,n.sampled[pop],prev[pop])
    test.results$pp[pop] <- rbinom(n.sim, n.pos, Se.1*Se.2) + 
      rbinom(n.sim, n.sampled[pop]-n.pos, (1-Sp.1)*(1-Sp.2))      #++
    test.results$pn[pop] <- rbinom(n.sim, n.pos, Se.1*(1-Se.2)) + 
      rbinom(n.sim, n.sampled[pop]-n.pos, (1-Sp.1)*Sp.2)          #+-
    test.results$np[pop] <- rbinom(n.sim, n.pos, (1-Se.1)*Se.2) + 
      rbinom(n.sim, n.sampled[pop]-n.pos, Sp.1*(1-Sp.2))          #-+
    test.results$nn[pop] <- n.sampled[pop]-test.results$pp[pop]-
      test.results$pn[pop] -test.results$np[pop]                  #--
  }

```

- What is wrong with this example?

### A better version

```{R}
  set.seed(1)
  n.sim <- 1
  n.pop <- 2
  prev <- c(0.25, 0.8)
  Se.1 <- Se.2 <- 0.8
  Sp.1 <- Sp.2 <- 0.95
  cond.prob.pos <- c(Se.1*Se.2, # probability a positive individual tests ++ 
                     (1-Se.1)*Se.2, # probability a positive individual tests -+ 
                     Se.1*(1-Se.2), # probability a positive individual tests + 
                     (1-Se.1)*(1-Se.2)) # probability a positive individual tests --
  cond.prob.neg <- c((1-Sp.1)*(1-Sp.2), # probability a negative individual tests ++
                     Sp.1*(1-Sp.2), # probability a negative individual tests -+
                     (1-Sp.1)*Sp.2, # probability a negative individual tests +-
                     Sp.1*Sp.2) # probability a negative individual tests --
  n.sampled <- c(100, 100)
  test.results <- matrix(nrow=4,ncol=length(prev), dimnames=list(test.result = c("pp","np","pn","nn"), population = c("a","b")))
  for(pop in 1:length(prev)){
    n.pos <- rbinom(n.sim,n.sampled[pop],prev[pop])
    n.neg <- n.sampled[pop] - n.pos
    test.results[,pop] <- rmultinom(n.sim, n.pos, cond.prob.pos) + 
      rmultinom(n.sim, n.neg, cond.prob.neg)
  }

```

## JAGS code

```{R h-w_JAGS}

cat(
"model{
  # Likelihood part:
  for (i in 1:n.pop) {
    p.test.result[1,i] <-prev[i]*Se[1]*Se[2] + (1-prev[i])*(1-Sp[1])*(1-Sp[2]) #pp
    p.test.result[3,i] <-prev[i]*(1-Se[1])*Se[2] + (1-prev[i])*(Sp[1])*(1-Sp[2]) #np
    p.test.result[2,i] <-prev[i]*Se[1]*(1-Se[2]) + (1-prev[i])*(1-Sp[1])*Sp[2] #pn
    p.test.result[4,i] <-prev[i]*(1-Se[1])*(1-Se[2]) + (1-prev[i])*Sp[1]*Sp[2] #nn
    test.results[,i] ~dmulti(p.test.result[,i], n.sampled[i])
  }
  
  
    
  # Prior part:
  for (pop in 1:n.pop)  {
    prev[pop] ~ dbeta(1,1)
  }
  for(test in 1:2)  {
    Se[test] ~dbeta(3,2)
    Sp[test] ~dbeta(3,2)
  }
  
  # Hooks for automatic integration with R:
  #data# test.results, n.sampled, n.pop
  #monitor# prev, Se, Sp
}
", file = "h-w.jags")
```

## Analysis

```{R h-w_analysis}

runjags.options(silent.jags=TRUE)
n.burnin <- n.sample <- 5000
results.jags <- run.jags('h-w.jags', n.chains=2, burnin=n.burnin, sample=n.sample)

pander(summary(results.jags))
```

## Graphs

```{R plots_h-w}

plot(results.jags)

```

## Exercise

  - 3 tests; 1 population
  - 7 parameters:
      + 3 test sensitivities
      + 3 test specificities
      + 1 prevalence
  - $2^3$ combinations: 7 df in the data
      + is this identifiable?
      + are the estimates unbiased?
      + what if prevalence is very low ~1%?
      + even with 1000 individuals only ~10 are positive
      + can't estimate Se well
      + does a biased estimate of Se bias our estimates of Sp and/or prevalence?


## Example R code

```{R}
simulation.3.test <- function(prev,n.sampled,Se,Sp) {
  if((length(prev)!=1)&(length(n.sampled)!=1)&(length(Se)!=3)&(length(Sp)!=3)) {
    print("Error in parameters sent to simulation.3.test")
    stop()
  }
  n.pos <- rbinom(1,n.sampled,prev)
  n.neg <- n.sampled - n.pos
  test.1 <- c(rbinom(n.pos,1,Se[1]), rbinom(n.neg,1,(1-Sp[1])))
  test.2 <- c(rbinom(n.pos,1,Se[2]), rbinom(n.neg,1,(1-Sp[2])))
  test.3 <- c(rbinom(n.pos,1,Se[3]), rbinom(n.neg,1,(1-Sp[3])))
  test.results <- c(
    sum(test.1 & test.2 & test.3),
    sum(test.1 & test.2 & !test.3),
    sum(test.1 & !test.2 & test.3),
    sum(test.1 & !test.2 & !test.3),
    sum(!test.1 & test.2 & test.3),
    sum(!test.1 & test.2 & !test.3),
    sum(!test.1 & !test.2 & test.3),
    sum(!test.1 & !test.2 & !test.3))
  names(test.results) <- c("ppp", "ppn", "pnp", "pnn", "npp", "npn", "nnp", "nnn")
  return(test.results)
}
```

## Example R/JAGS code

```{R}
cat(
"model{
  # Likelihood part:
  p.test.result[1] <-prev*Se[1]*Se[2]*Se[3] + (1-prev)*(1-Sp[1])*(1-Sp[2])*(1-Sp[3]) #ppp
  p.test.result[2] <-prev*Se[1]*Se[2]*(1-Se[3]) + (1-prev)*(1-Sp[1])*(1-Sp[2])*Sp[3] #ppn
  p.test.result[3] <-prev*Se[1]*(1-Se[2])*Se[3] + (1-prev)*(1-Sp[1])*Sp[2]*(1-Sp[3]) #pnp
  p.test.result[4] <-prev*Se[1]*(1-Se[2])*(1-Se[3]) + (1-prev)*(1-Sp[1])*Sp[2]*Sp[3] #pnn
  p.test.result[5] <-prev*(1-Se[1])*Se[2]*Se[3] + (1-prev)*Sp[1]*(1-Sp[2])*(1-Sp[3]) #npp
  p.test.result[6] <-prev*(1-Se[1])*Se[2]*(1-Se[3]) + (1-prev)*Sp[1]*(1-Sp[2])*Sp[3] #npn
  p.test.result[7] <-prev*(1-Se[1])*(1-Se[2])*Se[3] + (1-prev)*Sp[1]*Sp[2]*(1-Sp[3]) #nnp
  p.test.result[8] <-prev*(1-Se[1])*(1-Se[2])*(1-Se[3]) + (1-prev)*Sp[1]*Sp[2]*Sp[3] #nnn
  test.results ~dmulti(p.test.result, n.tested)
    
  # Prior part:
  prev ~ dbeta(1,1)
  for(test in 1:3)  {
    Se[test] ~dbeta(1,1)
    Sp[test] ~dbeta(1,1)
  }
  
  # Hooks for automatic integration with R:
  #data# test.results, n.tested
  #monitor# prev, Se, Sp
}
", file = "three.test.jags")

prev<- 0.50
n.tested <- 1000
Se <- c(0.8,0.8,0.95)
Sp <- c(0.95,0.99,0.8)
test.results <- simulation.3.test(prev,n.tested,Se,Sp)

runjags.options(silent.jags=TRUE)
n.burnin <- n.sample <- 5000
results.jags <- run.jags('three.test.jags', n.chains=2, burnin=n.burnin, sample=n.sample)

pander(summary(results.jags))

plot(results.jags)

```

## How good is our posterior?

- Eyeball posterior distribution
- Are the means (medians, modes?) close to the values used for the simulation
- If we wish to be more formal about this we would repeat the simulation-analysis cycle many (400+) times
  + this takes a long time, typically
  + which is a better (less biased) predictor: mean, median or mode
  + are the 95% Credible Intervals true 95% Confidence Intervals
  + varying the parameter values within sensible ranges
  
## Multiple simulations

```{R}
  set.seed(1)
  n.sim <- 1000
  n.pop <- 2
  comparison.df <- data.frame(prev = c(runif(n.sim, 0.05, 0.40), runif(n.sim, 0.7, 0.9)),
                              Se.1 = runif(n.sim, 0.65, 0.9),
                              Sp.1 = rbeta(n.sim, 21,1),
                              Se.2 = rbeta(n.sim, 17,5),
                              Se.2 = rbeta(n.sim, 19,3),
                              prev.1.median = numeric(n.sim),
                              prev.2.median = numeric(n.sim),
                              prev.1.mean = numeric(n.sim),
                              prev.2.mean = numeric(n.sim),
                              Se.1.lcl = numeric(n.sim),
                              Se.1.ucl = numeric(n.sim),
                              Se.2.lcl = numeric(n.sim),
                              Se.2.ucl = numeric(n.sim))
  for (sim in 1:n.sim) {
    ## Simulate data
    ## analyse data
    ## save appropriate summaries of results
  }
  ## compare results summaries with simulation parameter(s)
```
   

## Summary

- What is our interest?
  + which summary is better?
  + how accurate is the summary?
  + can we eliminate certain values?
  + 95% CI?
- What is the context?
  + range of possible values
  + effect of priors
  + convergence
  + sample size (see Matt)
- What if we believe that a parameter comes from a distribution, not a point value?



