---
title: "Session 3"
author: "Matt Denwood"
date: '2024-01-30'
output:
  html_document: default
  beamer_presentation:
    pandoc_args:
    - -t
    - beamer
    slide_level: 2
theme: metropolis
aspectratio: 169
colortheme: seahorse
header-includes: \input{../rsc/preamble}
params:
  presentation: no
subtitle: Sample Size Estimation
---

```{r setup, include=FALSE}
source("../rsc/setup.R")
load("../rsc/cache.rda")
```


## A note on coding styles  {.fragile}

My code looks a bit different to Giles's code, e.g.:

```{r}
# If necessary:
## install.packages(c("tidyverse","pbapply"))

library("tidyverse")
library("pbapply")


```

. . .

REMEMBER:  the coding style is not important as long as the output is the same!

# Background to sample size calculations

## Power calculation  {.fragile}

Power is defined as the proportion of experiments that can be expected to give p-values of <= 0.05 (or whatever alpha is chosen), conditional on the specified parameters.  Power calculations can be done using:

1. Approximation methods, e.g. power.t.test:

```{r}
power.t.test(n = 150, delta = 0.25, sd = 1)
```
- - -

2. Numerical methods i.e. by simulation:

A function to simulate data, then calculate and return a p-value:

```{r}
p_fun <- function(parameters){
  stopifnot(is.data.frame(parameters), nrow(parameters)==1L, "Size" %in% names(parameters))
  sample1 <- rnorm(parameters$Size, mean=0, sd=1)
  sample2 <- rnorm(parameters$Size, mean=0.25, sd=1)
  parameters |>
    mutate(P_val = t.test(sample1, sample2)$p.value)
}
```

```{r}
p_fun(tibble(Size = 150L))
```

- - -

There is randomness so this will be different every time it is run:

```{r}
p_fun(tibble(Size = 150L))
p_fun(tibble(Size = 150L))
```

- - -

So we must run it several times (e.g. 1000):

```{r}
tibble(Iteration = seq_len(1000L), Size = 150L) |>
  group_split(Iteration, Size) |>
  lapply(p_fun) |>
  bind_rows() ->
  pvals
```

. . .

And we calculate the power like so:

```{r}
pvals |>
  group_by(Size) |>
  summarise(Power = sum(P_val <= 0.05) / n(), .groups="drop")
```

## Sample size estimation  {.fragile}

The goal is typically to find the minimum sample size that corresponds to >= 80\% power, for a specified set of parameters.  This can be done in one of two ways:

1. Using approximation methods directly i.e.:

```{r}
power.t.test(n = NULL, delta = 0.25, sd = 1, power = 0.8)
```
- - -

2. By trying different sample sizes (using either approximation methods or simulation):

```{r}
tibble(Size = seq(100, 500, by=25)) |>
  group_split(Size) |>
  lapply(function(parameters){
    parameters |>
      mutate(Power = power.t.test(n = parameters$Size, delta = 0.25, sd = 1)$power)
  }) |>
  bind_rows() ->
  power_estimates
```

- - -

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(power_estimates, aes(x=Size, y=Power)) +
  geom_point() +
  stat_smooth(method="loess") +
  geom_hline(yintercept = 0.8)
```


# Sample size calculation for LCM

## Determining the objective  {.fragile}

Let's take a simple 2-test, 2-population Hui-Walter model as an example.

- There is (usually) no hypothesis to test, so we don't have a concept of power

- Our objective is to have narrow posterior (95\%) credible intervals ("precision"*)

- But for which parameter?

* Note: this is not exactly the same as the usual statistical definition of precision

## Types of parameter  {.fragile}

In general: 

- Experimental parameter:  structural things that we can control

- Parameter of interest:  things we want to estimate

- Nuisance parameters:  everything else

. . .

For t-tests: 

- Experimental parameter:  sample size

- Parameter of interest:  difference in means

- Nuisance parameters:  standard deviation

- - -

In general: 

- Experimental parameter:  structural things that we can control

- Parameter of interest:  things we want to estimate

- Nuisance parameters:  everything else

For Hui-Walter models:

- Experimental parameters:  number of samples from each population (and maybe number of populations)

- Parameters of interest:  sensitivities, specificities

- Nuisance parameters:  prevalences (and maybe correlation terms for >2 tests)


## Determining the objective  {.fragile}

We have 4 parameters of interest:  2 x Se, 2 x Sp.  Which are most important?

- Is sensitivity the sole objective?  NB: high-prevalence population will be prioritised.

- Is specificity the sole objective?  NB: low-prevalence population will be prioritised.

- Are sensitivity and specificity equally important?  If so, do we average the relative or absolute size of their 95\% CI?

. . .

- Would Youden's index be easier?

. . .

- One or both tests?

. . .

My suggestion:  define "precision" as the average width of 95\% CI for Youden's index (for either one or both tests)


## Simulating data  {.fragile}

This is best as a function that takes population-level and test-level inputs:

```{r eval=FALSE}
simulation_fun <- function(populations, tests){
  stopifnot(
    is.data.frame(populations), 
    nrow(populations) >= 2L,
    c("N","Prev") %in% names(populations),
    populations$N >= 1L,
    populations$N %% 1 == 0,
    populations$Prev >= 0, populations$Prev <= 1
  )
  stopifnot(
    is.data.frame(tests), 
    nrow(tests) >= 2L,
    c("Se","Sp") %in% names(tests),
    tests$Se >= 0, tests$Se <= 1,
    tests$Sp >= 0, tests$Sp <= 1
  )
  ## Do some stuff like from session 2 and return the simulated dataset
  ## See the exercise for a complete function!
}
```

- - -

Output looks like:

```{r}
tests <- tribble(
  ~Se, ~Sp,
  0.8, 0.99,
  0.9, 0.95
)

populations <- tribble(
  ~N, ~Prev,
  100, 0.1,
  100, 0.4
)

(data <- simulation_fun(populations, tests))
```


## Analying data  {.fragile}

Also best as a function taking the data, burnin and sample iterations as inputs:

```{r eval=FALSE}
analysis_fun <- function(data, burnin=1000L, sample=5000L){
  stopifnot(is.matrix(data), nrow(data)==4L, ncol(data)==2L, data>=0L)
  ## Do some stuff like from session 2 to analyse the data
  ## See the exercise for a complete function 
  results |>
    summary(vars=c("youden","se","sp")) |>
    as.data.frame() |>
    rownames_to_column("Variable")
}
```

- - -

Output looks like:

```{r}
analysis_fun(data)
```

## A quick note on label switching

I now recommend this method of specifying minimally informative priors:

```{r eval=FALSE}
model{
  ### Rest of the model as usual
  
  for(t in 1:2){
    se[t] ~ dbeta(2,1)
    sp[t] ~ dbeta(2,1)
    youden[t] <- se[t]+sp[t]-1.0
    AcceptTest[t] ~ dbern(ifelse(youden[t] >= 0.0, 1, 0))
  }
 #data# AcceptTest 
}

AcceptTest <- c(1,1)
```

. . .

More on this during my presentation tomorrow!

## Combining the two  {.fragile}

```{r}
summary_fun <- function(parameters, iterations, cl=NULL, burnin=1000L, sample=5000L){
  stopifnot(is_tibble(parameters))
  stopifnot(iterations >= 1L)
  
  parameters |>
    mutate(ParameterSet = row_number()) |>
    expand_grid(Iteration = seq_len(iterations)) |>
    rowwise() |>
    group_split() |>
    pblapply(function(x){
      simulation_fun(x$Populations[[1]], x$Tests[[1]]) |>
        analysis_fun(burnin=burnin, sample=sample) |>
        bind_cols(x)
    }, cl=cl) |>
    bind_rows() |>
    mutate(WidthCI = Upper95 - Lower95) |>
    group_by(ParameterSet, Variable) |>
    summarise(MeanEst = mean(Mean), MeanWidth = mean(WidthCI), MeanLCI = mean(Lower95), MeanUCI = mean(Upper95), .groups="drop") |>
    full_join(parameters |> mutate(ParameterSet = row_number()), by="ParameterSet")
}
```

Guess what ... I will use another function!  This function might look scary if you are not used to this way of coding ... but don't worry too much about exactly what it does.

- - -

Output looks like:

```{r}
parameters <- tibble(Populations=list(populations), Tests=list(tests))
summary_fun(parameters, 10L)
```

## Visualisaing the results  {.fragile}

```{r echo=FALSE, message=FALSE, warning=FALSE}
summary_results |>
  filter(str_detect(Variable, "youden")) |>
  group_by(Split) |>
  summarise(Variable = "precision", MeanWidth = mean(MeanWidth)) |>
  bind_rows(
    summary_results |> select(Split, Variable, MeanWidth)
  ) ->
  plotdata

plotdata |>
  filter(str_detect(Variable, "^s")) |>
  ggplot(aes(x=Split, y=MeanWidth, col=Variable)) +
  geom_smooth(se=FALSE) + 
  geom_point()
```

Here is an example with a total of 500 samples, which are allocated between populations differently.  In general, Se is better estimated with with more samples in (the higher-prevalence) population 2, and Sp is better estimated with with more samples in (the lower-prevalence) population 1.

- - -

```{r echo=FALSE, message=FALSE, warning=FALSE}
plotdata |>
  filter(!str_detect(Variable, "^s")) |>
  ggplot(aes(x=Split, y=MeanWidth, col=Variable)) +
  geom_smooth(se=FALSE) + 
  geom_point()
```

It is easier to see a balance between these using Youden's index or our "precision".

The optimum is around a 40/60 split, but of course this could be better defined using a more refined resolution for the split (and/or a higher number of iterations - this is based on 200 iterations per parameter set).

## Exercises {.fragile}

1. Either have a go at writing your own functions for simulation_fun and analysis_fun (based on the code from earlier today), or just look at the function code given in the HTML file (although make sure you read it through so that you understand it!).

2. Re-create the "visualising the results" plot I have given above (using either your own functions or the functions I have provided below).  Test #1 has Se/Sp of 0.8/0.99 and Test #2 has Se/Sp of 0.9/0.95.  Prevalences in the two populations are 10\% and 40\%, and the total sample size is 500.

3. Assuming that the optimum distribution of tests between the two populations is always around 40\% / 60\% for these test/prevalence estimates, create a plot showing how precision increases with total sample size of between 100 and 1000.

4. How much does the precision also depend on the parameters of interest (diagnostic test performance) and nuisance parameters (prevalences)?

`r exercise_start()`

## Functions

An example function for data simulation:

```{r}
simulation_fun <- function(populations, tests){
  stopifnot(
    is.data.frame(populations), 
    nrow(populations) >= 2L,
    c("N","Prev") %in% names(populations),
    populations$N >= 1L,
    populations$N %% 1 == 0,
    populations$Prev >= 0, populations$Prev <= 1
  )
  stopifnot(
    is.data.frame(tests), 
    nrow(tests) >= 2L,
    c("Se","Sp") %in% names(tests),
    tests$Se >= 0, tests$Se <= 1,
    tests$Sp >= 0, tests$Sp <= 1
  )
  
  populations |>
    mutate(Population = fct(str_c("Pop", row_number()))) |>
    group_by(Population, N, Prev) |>
    reframe(Individual = str_c(Population, "_", seq_len(N))) |>
    ungroup() |>
    mutate(Status = rbinom(n(), 1L, Prev)) |>
    expand_grid(
      tests |>
        mutate(TestNum = fct(str_c("Test", row_number())))
    ) |>
    mutate(Result = rbinom(n(), 1L, Status*Se + (1-Status)*(1-Sp))) |>
    select(Population, Individual, TestNum, Result) |>
    pivot_wider(names_from="TestNum", values_from=Result) |>
    count(Population, Test1, Test2) |>
    complete(Population, Test1, Test2, fill = list(n = 0L)) |>
    arrange(Population, Test2, Test1) ->
    data
  stopifnot(nrow(data)==8L, sum(data$n) == sum(populations$N))
  return(data |> pull(n) |> matrix(ncol=2))
}
```

This can be used like so:

```{r}
tests <- tribble(
  ~Se, ~Sp,
  0.8, 0.99,
  0.9, 0.95
)

populations <- tribble(
  ~N, ~Prev,
  100, 0.1,
  100, 0.4
)

(data <- simulation_fun(populations, tests))
```

An example function for analysis:

```{r}
analysis_fun <- function(data, burnin=1000L, sample=5000L){
  stopifnot(is.matrix(data), nrow(data)==4L, ncol(data)==2L, data>=0L)
  
  ## A minimal model:
  model <- "model{
	for(p in 1:Populations){
		Tally[1:4,p] ~ dmulti(prob[1:4,p], N[p])
		prob[1,p] <- prev[p] * ((1-se[1])*(1-se[2]))  +  (1-prev[p]) * (sp[1])*(sp[2])
		prob[2,p] <- prev[p] * (se[1]*(1-se[2]))  +  (1-prev[p]) * (1-sp[1])*sp[2]
		prob[3,p] <- prev[p] * ((1-se[1])*(se[2]))  +  (1-prev[p]) * (sp[1])*(1-sp[2])
		prob[4,p] <- prev[p] * (se[1]*se[2])  +  (1-prev[p]) * (1-sp[1])*(1-sp[2])
	}
	for(p in 1:Populations){
  	prev[p] ~ dbeta(1,1)
	}
  for(t in 1:2){
    se[t] ~ dbeta(2,1)
    sp[t] ~ dbeta(2,1)
    youden[t] <- se[t]+sp[t]-1.0
    AcceptTest[t] ~ dbern(ifelse(youden[t] >= 0.0, 1, 0))
  }
  }"
  
  datalist <- list(Tally = data, N = apply(data, 2L, sum), Populations=2L, AcceptTest=c(1,1))
  
  run.jags(model, monitor=c("youden","se","sp"), data=datalist) |>
    summary(vars=c("youden","se","sp")) |>
    as.data.frame() |>
    rownames_to_column("Variable")
}
```

This can be used as follows:

```{r}
analysis_fun(data)
```

It will help to set the following options to suppress output:

```{r}
runjags.options(silent.jags=TRUE, inits.warning=FALSE, predraw.plots=FALSE)
```

And now we can use our previously defined summary function (copied here for convenience):

```{r}
summary_fun <- function(parameters, iterations, cl=NULL, burnin=1000L, sample=5000L){
  stopifnot(is_tibble(parameters))
  stopifnot(iterations >= 1L)
  
  parameters |>
    mutate(ParameterSet = row_number()) |>
    expand_grid(Iteration = seq_len(iterations)) |>
    rowwise() |>
    group_split() |>
    pblapply(function(x){
      simulation_fun(x$Populations[[1]], x$Tests[[1]]) |>
        analysis_fun(burnin=burnin, sample=sample) |>
        bind_cols(x)
    }, cl=cl) |>
    bind_rows() |>
    mutate(WidthCI = Upper95 - Lower95) |>
    group_by(ParameterSet, Variable) |>
    summarise(MeanEst = mean(Mean), MeanWidth = mean(WidthCI), MeanLCI = mean(Lower95), MeanUCI = mean(Upper95), .groups="drop") |>
    full_join(parameters |> mutate(ParameterSet = row_number()), by="ParameterSet")
}
```

Using code like this (note that Populations and Tests are lists of tibbles, contained within another tibble - see https://bookdown.org/Maxine/r4ds/nesting.html# for more details on why this is a good idea):

```{r}
parameters <- tibble(Populations=list(populations), Tests=list(tests))
summaries <- summary_fun(parameters, iterations=20L)
```

From this, we can define precision as the average of the MeanWidth of the two Youden's index parameters:

```{r}
summaries |>
  filter(str_detect(Variable, "youden")) |>
  group_by(ParameterSet, Populations, Tests) |>
  summarise(Precision = mean(MeanWidth), .groups="drop")
```


## Solutions

1. This just takes practice! If you prefer not to use tidyverse then it is perfectly valid to code this in a different way, but I would still strongly suggest using functions to break the task into smaller pieces.

2. Here is the basic code I used (except with more iterations):

```{r message=FALSE, warning=FALSE}
tibble(Split = seq(0.1, 0.9, by=0.1)) |>
  mutate(TotalSamples = 500L, N1 = round(TotalSamples*Split), N2 = TotalSamples-N1) |>
  rowwise() |>
  mutate(Populations = list(tibble(N = c(N1, N2), Prev = c(0.1, 0.4)))) |>
  mutate(Tests = list(tests)) |>
  ungroup() |>
  summary_fun(iterations = 10L, cl=NULL) ->
  summary_results

summary_results |>
  filter(str_detect(Variable, "youden")) |>
  group_by(Split) |>
  summarise(Variable = "precision", MeanWidth = mean(MeanWidth)) |>
  bind_rows(
    summary_results |> select(Split, Variable, MeanWidth)
  ) |>
  ggplot(aes(x=Split, y=MeanWidth, col=Variable)) +
  geom_smooth(se=FALSE) + 
  geom_point()
```

3. This is very easy using very similar code to before:

```{r message=FALSE, warning=FALSE}
tibble(TotalSamples = seq(100,1000,by=100), N1 = round(TotalSamples*0.4), N2 = TotalSamples-N1) |>
  rowwise() |>
  mutate(Populations = list(tibble(N = c(N1, N2), Prev = c(0.1, 0.4)))) |>
  mutate(Tests = list(tests)) |>
  ungroup() |>
  summary_fun(iterations = 10L, cl=NULL) ->
  summary_results

summary_results |>
  filter(str_detect(Variable, "youden")) |>
  group_by(TotalSamples) |>
  summarise(Precision = mean(MeanWidth)) |>
  ggplot(aes(x=TotalSamples, y=Precision)) +
  geom_smooth(se=FALSE) + 
  geom_point()
```

4. The answer is "a lot" - so results are always scenario specific!

```{r include=FALSE}
#save(simulation_fun, analysis_fun, summary_fun, summary_results, file="rsc/cache.rda")
```

`r exercise_end()`


```{r include=FALSE}
unlink(cleanup)
```
